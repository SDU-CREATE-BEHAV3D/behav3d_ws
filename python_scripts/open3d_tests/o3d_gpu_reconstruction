import argparse
import datetime
from pathlib import Path
import numpy as np
import yaml
import cv2
import open3d as o3d
import open3d.core as o3c
from scipy.spatial.transform import Rotation as R
import json
import os


# ---------- INTRINSICS / EXTRINSICS ----------
def load_camera_intrinsics(file_path):
    # check file existence
    if not os.path.isfile(file_path):
	   print(f"The file {file_path} does not exist.")
	   return None, None

    # read YAML file using OpenCV
    fs = cv2.FileStorage(file_path, cv2.FILE_STORAGE_READ)
    if not fs.isOpened():
	   print(f"Failed to open the file {file_path}.")
	   return None, None

    # extract parameters
    width  = int(fs.getNode("image_width").real())
    height = int(fs.getNode("image_height").real())
    camera_matrix = fs.getNode("camera_matrix").mat()
    dist_coeffs = fs.getNode("distortion_coefficients").mat()
    fs.release()

    # convert intrinsics to Open3D format
    intrinsic = o3d.camera.PinholeCameraIntrinsic(
	   width, height,
	   camera_matrix[0, 0],  # fx
	   camera_matrix[1, 1],  # fy
	   camera_matrix[0, 2],  # cx
	   camera_matrix[1, 2],  # cy
    )

    return intrinsic, dist_coeffs
# print(load_camera_intrinsics("/home/lab/behav3d_ws/captures/session-20250905_180510_mancap/calib/depth_intrinsics.yaml"))


def load_camera_extrinsics(file_path):
    # check file existence
    if not os.path.isfile(file_path):
	   print(f"The file {file_path} does not exist.")
	   return None

    # load JSON file
    with open(file_path, 'r') as f:
	   data = json.load(f)

    # extract translation and quaternion
    translation = np.array(data["translation_m"])
    quaternion = np.array(data["quaternion_xyzw"])
    rotation = R.from_quat(quaternion).as_matrix()

    # build 4x4 transformation matrix (camera -> tool)
    T_cam_to_tool = np.eye(4)
    T_cam_to_tool[:3, :3] = rotation
    T_cam_to_tool[:3, 3] = translation

    return T_cam_to_tool
# print(load_camera_extrinsics("/home/lab/behav3d_ws/captures/session-20250905_180510_mancap/calib/handeye_result_final.json"))


def load_robot_poses_manifest(manifest):
#     # check file existence
#     if not os.path.isfile(file_path):
#         print(f"The file {file_path} does not exist.")
#         return None

#     # load YAML manifest
#     with open(file_path, 'r') as f:
#         manifest = yaml.safe_load(f)

    session_info = manifest.get("session", {})
    base_path = session_info.get("path", None)
    if not base_path or not os.path.isdir(base_path):
	   raise ValueError(f"Invalid or missing capture path in manifest: {base_path}")

    captures = manifest.get("captures", [])
    parsed_captures = []

    # parse each capture entry
    for capture in captures:
	   rgb_rel = capture.get("rgb")
	   depth_rel = capture.get("depth")
	   ir_rel = capture.get("ir")
	   pose = capture.get("pose_tool0", {})   # correct key name
	   timestamp = capture.get("timestamp", None)

	   # build absolute paths
	   rgb_path = os.path.join(base_path, rgb_rel) if rgb_rel else None
	   depth_path = os.path.join(base_path, depth_rel) if depth_rel else None
	   ir_path = os.path.join(base_path, ir_rel) if ir_rel else None

	   # convert pose to 4x4 matrix
	   translation = np.array(pose.get("position", [0, 0, 0]))
	   quaternion = np.array(pose.get("orientation_xyzw", [0, 0, 0, 1]))
	   rotation = R.from_quat(quaternion).as_matrix()
	   pose_matrix = np.eye(4)
	   pose_matrix[:3, :3] = rotation
	   pose_matrix[:3, 3] = translation

	   # append structured data
	   parsed_captures.append({
		  "index": capture.get("index", None),
		  "timestamp": timestamp,
		  "rgb_path": rgb_path,
		  "depth_path": depth_path,
		  "ir_path": ir_path,
		  "tool0_matrix": pose_matrix,
		  "camera_pose_materix"
	   })

    return parsed_captures, intrinsics, extrinsics
# print(load_robot_poses_manifest("/home/lab/behav3d_ws/captures/251021_115853/scan_1/manifest.yaml"))

def import_pose_tree(manifest, extrinsics):
	session_info = manifest.get("session", {})
	base_path = session_info.get("path", None)
	if not base_path or not os.path.isdir(base_path):
		raise ValueError(f"Invalid or missing capture path in manifest: {base_path}")

	captures = manifest.get("captures", [])
	pose_tree = []

    # parse each capture entry
	for capture in captures:
		rgb_rel = capture.get("rgb")
		depth_rel = capture.get("depth")
		ir_rel = capture.get("ir")
		pose = capture.get("pose_tool0", {})   # correct key name
		timestamp = capture.get("timestamp", None)

		# build absolute paths
		rgb_path = os.path.join(base_path, rgb_rel) if rgb_rel else None
		depth_path = os.path.join(base_path, depth_rel) if depth_rel else None
		ir_path = os.path.join(base_path, ir_rel) if ir_rel else None

		# convert pose to 4x4 matrix
		translation = np.array(pose.get("position", [0, 0, 0]))
		quaternion = np.array(pose.get("orientation_xyzw", [0, 0, 0, 1]))
		rotation = R.from_quat(quaternion).as_matrix()
		pose_matrix = np.eye(4)
		pose_matrix[:3, :3] = rotation
		pose_matrix[:3, 3] = translation

	   	# append structured data
		pose_tree.append({
			"index": capture.get("index", None),
			"timestamp": timestamp,
			"rgb_path": rgb_path,
			"depth_path": depth_path,
			"ir_path": ir_path,
			"tool0_matrix": pose_matrix,
			"camera_pose_matrix": pose_matrix @ extrinsics
		})
	return pose_tree

def export_trajectory(camera_poses, output_dir):
	"""
	Computes and logs the robot's trajectory based on the transformations to the camera frame.

	:return: A list of transformation matrices representing the robot's trajectory.
	"""

	Ts = np.asarray(camera_poses).reshape((-1,4,4))
	n = len(Ts)
	result = []

	path = os.path.join(output_dir, 'trajectory.log')
	with open(path, 'w') as f:
		for i in range(n):
			f.write('{} {} {}\n'.format(i-1, i, n))

			T = np.asarray(Ts[i]).reshape((4,4))
		
			T[:3, 3] *= 0.001 # convert robot XYZ position from mm to m

			result.append(T)
			s = np.array2string(T)
			s = re.sub('[\[\]]', '', s)

			f.write('{}\n'.format(s))
	return result

def parse_manifest(file_path):
	if not os.path.isfile(file_path):
		print(f"The file {file_path} does not exist.")
		return None

	# load YAML manifest
	with open(file_path, 'r') as f:
	   manifest = yaml.safe_load(f)

	intrinsics = load_intrinsics(manifest)
	extrinsics = load_extrinsics(manifest)
	pose_tree = import_pose_tree(manifest, extrinsics)
	export_trajectory([pose["camera_pose_matrix"] for pose in pose_tree], "camera_poses.log")

	tmp = []
	for pose in pose_tree:
		tmp.append(pose["camera_pose_matrix"])

	return pose_tree, intrinsics, extrinsics

    # compute camera pose in base/world frame
def transform_robot_to_camera_pose(parsed_captures, T_cam_to_tool):
    transformed_captures = []
    for cap in parsed_captures:
	   T_tool_to_base = cap["pose_matrix"]                # from robot
	   T_cam_to_base = T_tool_to_base @ T_cam_to_tool     # correct order
	   cap["camera_pose"] = T_cam_to_base
	   transformed_captures.append(cap)
    return transformed_captures

# load depth image
def load_depth_image(file_path):
    if not os.path.isfile(file_path):
	   print(f"The file {file_path} does not exist.")
	   return None
    depth_image = o3d.io.read_image(file_path)
    return depth_image

#
[pose["depth_path"] for pose in pose_tree]